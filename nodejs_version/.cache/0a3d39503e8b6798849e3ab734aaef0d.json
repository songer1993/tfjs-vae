{"dependencies":[{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\package.json","includedInParent":true,"mtime":1528200878026},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\.babelrc","includedInParent":true,"mtime":1528197961732},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\node_modules\\@tensorflow\\tfjs-layers\\package.json","includedInParent":true,"mtime":1524501157000},{"name":"../errors","loc":{"line":3,"column":23}},{"name":"./topology","loc":{"line":4,"column":25}}],"generated":{"js":"\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar errors_1 = require(\"../errors\");\nvar topology_1 = require(\"./topology\");\nfunction assertFeedCompatibility(key, val) {\n    if (key.dtype != null && key.dtype !== val.dtype) {\n        throw new errors_1.ValueError(\"The dtype of the feed (\" + val.dtype + \") is incompatible with that of \" +\n            (\"the key '\" + key.name + \"' (\" + key.dtype + \").\"));\n    }\n    if (key.shape != null) {\n        if (key.shape.length !== val.shape.length) {\n            throw new errors_1.ValueError(\"The rank of feed (\" + val.shape.length + \") does not match the rank of \" +\n                (\"the key (\" + key.shape.length + \").\"));\n        }\n        for (var i = 0; i < key.shape.length; ++i) {\n            if (key.shape[i] != null && key.shape[i] !== val.shape[i]) {\n                throw new errors_1.ValueError(\"The \" + i + \"-th dimension of the feed (\" + val.shape[i] + \") is \" +\n                    (\"incompatible with that of the key (\" + key.shape[i] + \").\"));\n            }\n        }\n    }\n}\nvar FeedDict = (function () {\n    function FeedDict(feeds) {\n        this.id2Value = {};\n        if (feeds instanceof FeedDict) {\n            for (var id in feeds.id2Value) {\n                this.id2Value[id] = feeds.id2Value[id];\n            }\n        }\n        else {\n            if (feeds == null) {\n                return;\n            }\n            for (var _i = 0, feeds_1 = feeds; _i < feeds_1.length; _i++) {\n                var feed = feeds_1[_i];\n                this.add(feed.key, feed.value);\n            }\n        }\n    }\n    FeedDict.prototype.add = function (key, value) {\n        assertFeedCompatibility(key, value);\n        if (this.id2Value[key.id] == null) {\n            this.id2Value[key.id] = value;\n        }\n        else {\n            throw new errors_1.ValueError(\"Duplicate key: name=\" + key.name + \", id=\" + key.id);\n        }\n        return this;\n    };\n    FeedDict.prototype.addFeed = function (feed) {\n        this.add(feed.key, feed.value);\n    };\n    FeedDict.prototype.hasKey = function (key) {\n        return this.id2Value[key.id] != null;\n    };\n    FeedDict.prototype.getValue = function (key) {\n        if (this.id2Value[key.id] == null) {\n            throw new errors_1.ValueError(\"Nonexistent key: \" + JSON.stringify(key));\n        }\n        else {\n            return this.id2Value[key.id];\n        }\n    };\n    return FeedDict;\n}());\nexports.FeedDict = FeedDict;\nfunction execute(fetches, feedDict, kwargs) {\n    var arrayFetches = Array.isArray(fetches);\n    var fetchArray = arrayFetches ? fetches : [fetches];\n    var outputs = [];\n    var internalFeedDict = new FeedDict(feedDict);\n    for (var _i = 0, fetchArray_1 = fetchArray; _i < fetchArray_1.length; _i++) {\n        var fetch_1 = fetchArray_1[_i];\n        outputs.push(executeInternal(fetch_1, internalFeedDict, kwargs));\n    }\n    return arrayFetches ? outputs : outputs[0];\n}\nexports.execute = execute;\nfunction executeInternal(fetch, internalFeedDict, kwargs) {\n    if (internalFeedDict.hasKey(fetch)) {\n        return internalFeedDict.getValue(fetch);\n    }\n    if (fetch.sourceLayer instanceof topology_1.InputLayer) {\n        throw new errors_1.ValueError(\"Missing a feed value for SymbolicTensor from InputLayer \" +\n            (\"'\" + topology_1.InputLayer.name + \"'\"));\n    }\n    var inputs = fetch.inputs;\n    var inputValues = [];\n    for (var _i = 0, inputs_1 = inputs; _i < inputs_1.length; _i++) {\n        var input = inputs_1[_i];\n        var inputVal = executeInternal(input, internalFeedDict, kwargs);\n        inputValues.push(inputVal);\n    }\n    var output = fetch.sourceLayer.apply(inputValues, kwargs);\n    if (!Array.isArray(output)) {\n        output = [output];\n    }\n    var layerOutputs = getNodeOutputs(fetch);\n    var outputSymbolicTensors = Array.isArray(layerOutputs) ? layerOutputs : [layerOutputs];\n    for (var i = 0; i < outputSymbolicTensors.length; ++i) {\n        internalFeedDict.add(outputSymbolicTensors[i], output[i]);\n    }\n    return output.length === 1 ? output[0] : output[fetch.outputTensorIndex];\n}\nfunction getNodeOutputs(fetch) {\n    var layerOutputs;\n    if (fetch.sourceLayer.inboundNodes.length === 1) {\n        layerOutputs = fetch.sourceLayer.output;\n    }\n    else {\n        var nodeIndex = null;\n        for (var i = 0; i < fetch.sourceLayer.inboundNodes.length; ++i) {\n            for (var _i = 0, _a = fetch.sourceLayer.inboundNodes[i]\n                .outputTensors; _i < _a.length; _i++) {\n                var outputTensor = _a[_i];\n                if (outputTensor.id === fetch.id) {\n                    nodeIndex = i;\n                    break;\n                }\n            }\n        }\n        layerOutputs = fetch.sourceLayer.getOutputAt(nodeIndex);\n    }\n    return layerOutputs;\n}\n"},"hash":"6dedefccbe29cbfff08c4a06c3f433b0","cacheData":{"env":{}}}