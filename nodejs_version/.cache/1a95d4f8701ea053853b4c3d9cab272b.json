{"dependencies":[{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\package.json","includedInParent":true,"mtime":1528200878026},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\.babelrc","includedInParent":true,"mtime":1528197961732},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\node_modules\\@tensorflow\\tfjs-layers\\package.json","includedInParent":true,"mtime":1524501157000},{"name":"@tensorflow/tfjs-core","loc":{"line":55,"column":26}},{"name":"../backend/tfjs_backend","loc":{"line":56,"column":16}},{"name":"../callbacks","loc":{"line":57,"column":26}},{"name":"../errors","loc":{"line":58,"column":23}},{"name":"../losses","loc":{"line":59,"column":21}},{"name":"../metrics","loc":{"line":60,"column":22}},{"name":"../optimizers","loc":{"line":61,"column":25}},{"name":"../utils/generic_utils","loc":{"line":62,"column":30}},{"name":"../utils/math_utils","loc":{"line":63,"column":27}},{"name":"./executor","loc":{"line":64,"column":25}},{"name":"./topology","loc":{"line":65,"column":25}}],"generated":{"js":"\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [0, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfc = require(\"@tensorflow/tfjs-core\");\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar K = require(\"../backend/tfjs_backend\");\nvar callbacks_1 = require(\"../callbacks\");\nvar errors_1 = require(\"../errors\");\nvar losses = require(\"../losses\");\nvar Metrics = require(\"../metrics\");\nvar optimizers = require(\"../optimizers\");\nvar generic_utils_1 = require(\"../utils/generic_utils\");\nvar math_utils_1 = require(\"../utils/math_utils\");\nvar executor_1 = require(\"./executor\");\nvar topology_1 = require(\"./topology\");\nfunction isDataTensor(x) {\n    return x instanceof tfjs_core_1.Tensor;\n}\nexports.isDataTensor = isDataTensor;\nfunction isDataArray(x) {\n    return Array.isArray(x);\n}\nexports.isDataArray = isDataArray;\nfunction isDataDict(x) {\n    return !isDataTensor(x) && !isDataArray(x);\n}\nexports.isDataDict = isDataDict;\nfunction standardizeInputData(data, names, shapes, checkBatchAxis, exceptionPrefix) {\n    if (checkBatchAxis === void 0) { checkBatchAxis = true; }\n    if (exceptionPrefix === void 0) { exceptionPrefix = ''; }\n    if (names == null || names.length === 0) {\n        if (data != null) {\n            var gotUnexpectedData = false;\n            if (isDataArray(data) && data.length > 0) {\n                gotUnexpectedData = true;\n            }\n            else if (isDataDict(data)) {\n                for (var key in data) {\n                    if (data.hasOwnProperty(key)) {\n                        gotUnexpectedData = true;\n                        break;\n                    }\n                }\n            }\n            else {\n                gotUnexpectedData = true;\n            }\n            if (gotUnexpectedData) {\n                throw new errors_1.ValueError(\"Error when checking model \" + exceptionPrefix + \" expected no data, \" +\n                    (\"but got \" + data));\n            }\n        }\n        return [];\n    }\n    if (data == null) {\n        return names.map(function (name) { return null; });\n    }\n    var arrays;\n    if (isDataDict(data)) {\n        data = data;\n        arrays = [];\n        for (var _i = 0, names_1 = names; _i < names_1.length; _i++) {\n            var name_1 = names_1[_i];\n            if (data[name_1] == null) {\n                throw new errors_1.ValueError(\"No data provided for \\\"\" + name_1 + \"\\\". Need data for each key in: \" +\n                    (\"\" + names));\n            }\n            arrays.push(data[name_1]);\n        }\n    }\n    else if (isDataArray(data)) {\n        data = data;\n        if (data.length !== names.length) {\n            throw new errors_1.ValueError(\"Error when checking model \" + exceptionPrefix + \": the Array of \" +\n                \"Tensors that you are passing to your model is not the size the \" +\n                (\"model expected. Expected to see \" + names.length + \" Tensor(s), but \") +\n                (\"instead got the following list of Tensor(s): \" + data));\n        }\n        arrays = data;\n    }\n    else {\n        data = data;\n        if (names.length > 1) {\n            throw new errors_1.ValueError(\"The model \" + exceptionPrefix + \" expects \" + names.length + \" Tensor(s), \" +\n                (\"but only received one Tensor. Found: Tensor with shape \" + data.shape));\n        }\n        arrays = [data];\n    }\n    for (var i = 0; i < names.length; ++i) {\n        var array = arrays[i];\n        if (array.shape.length === 1) {\n            arrays[i] = K.expandDims(array, 1);\n        }\n    }\n    if (shapes != null) {\n        for (var i = 0; i < names.length; ++i) {\n            if (shapes[i] == null) {\n                continue;\n            }\n            var array = arrays[i];\n            if (array.shape.length !== shapes[i].length) {\n                throw new errors_1.ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + names[i] + \" \" +\n                    (\"to have \" + shapes[i].length + \" dimension(s). but got array with \") +\n                    (\"shape \" + array.shape));\n            }\n            for (var j = 0; j < shapes[i].length; ++j) {\n                if (j === 0 && !checkBatchAxis) {\n                    continue;\n                }\n                var dim = array.shape[j];\n                var refDim = shapes[i][j];\n                if (refDim != null && refDim >= 0 && dim !== refDim) {\n                    throw new errors_1.ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + names[i] + \" \" +\n                        (\"to have shape [\" + shapes[i] + \"], but got array with shape \") +\n                        (\"[\" + array.shape + \"].\"));\n                }\n            }\n        }\n    }\n    return arrays;\n}\nexports.standardizeInputData = standardizeInputData;\nfunction checkArrayLengths(inputs, targets, weights) {\n    var setX = generic_utils_1.unique(inputs.map(function (input) { return input.shape[0]; }));\n    setX.sort();\n    var setY = generic_utils_1.unique(targets.map(function (target) { return target.shape[0]; }));\n    setY.sort();\n    if (setX.length > 1) {\n        throw new errors_1.ValueError(\"All input Tensors (x) should have the same number of samples. \" +\n            \"Got array shapes: \" +\n            (\"\" + JSON.stringify(inputs.map(function (input) { return input.shape; }))));\n    }\n    if (setY.length > 1) {\n        throw new errors_1.ValueError(\"All target Tensors (y) should have the same number of samples. \" +\n            \"Got array shapes: \" +\n            (\"\" + JSON.stringify(targets.map(function (target) { return target.shape; }))));\n    }\n    if (setX.length > 0 && setY.length > 0 && !tfjs_core_1.util.arraysEqual(setX, setY)) {\n        throw new errors_1.ValueError(\"Input Tensors should have the same number of samples as target \" +\n            (\"Tensors. Found \" + setX[0] + \" input sample(s) and \" + setY[0] + \" target \") +\n            \"sample(s).\");\n    }\n}\nexports.checkArrayLengths = checkArrayLengths;\nfunction checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {\n    var keyLosses = [\n        losses.meanSquaredError, losses.binaryCrossentropy,\n        losses.categoricalCrossentropy\n    ];\n    for (var i = 0; i < targets.length; ++i) {\n        var y = targets[i];\n        var loss = lossFns[i];\n        var shape = outputShapes[i];\n        if (loss == null) {\n            continue;\n        }\n        if (loss === losses.categoricalCrossentropy) {\n            if (y.shape[y.shape.length - 1] === 1) {\n                throw new errors_1.ValueError(\"You are passing a target array of shape \" + y.shape + \" while using \" +\n                    \"a loss 'categorical_crossentropy'. 'categorical_crossentropy'\" +\n                    \"expects targets to be binary matrices (1s and 0s) of shape \" +\n                    \"[samples, classes].\");\n            }\n        }\n        if (keyLosses.indexOf(loss) !== -1) {\n            var slicedYShape = y.shape.slice(1);\n            var slicedShape = shape.slice(1);\n            for (var j = 0; j < slicedYShape.length; ++j) {\n                var targetDim = slicedYShape[j];\n                var outDim = slicedShape[j];\n                if (outDim != null && targetDim !== outDim) {\n                    throw new errors_1.ValueError(\"A target Tensor with shape \" + y.shape + \" was passed for an \" +\n                        (\"output of shape \" + shape + \", while using a loss function that \") +\n                        \"expects targets to have the same shape as the output.\");\n                }\n            }\n        }\n    }\n}\nfunction makeBatches(size, batchSize) {\n    var output = [];\n    var batchStart = 0;\n    var batchEnd = null;\n    while (batchStart < size) {\n        batchEnd = batchStart + batchSize;\n        if (batchEnd >= size) {\n            batchEnd = size;\n        }\n        output.push([batchStart, batchEnd]);\n        batchStart = batchEnd;\n    }\n    return output;\n}\nexports.makeBatches = makeBatches;\nfunction sliceArrays(arrays, start, stop) {\n    if (arrays == null) {\n        return [null];\n    }\n    else if (Array.isArray(arrays)) {\n        return arrays.map(function (array) { return K.sliceAlongFirstAxis(array, start, stop - start); });\n    }\n    else {\n        return K.sliceAlongFirstAxis(arrays, start, stop - start);\n    }\n}\nfunction sliceArraysByIndices(arrays, indices) {\n    if (arrays == null) {\n        return null;\n    }\n    else if (Array.isArray(arrays)) {\n        return arrays.map(function (array) { return sliceArraysByIndices(array, indices); });\n    }\n    else {\n        return K.gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n}\nexports.sliceArraysByIndices = sliceArraysByIndices;\nfunction checkInputData(data, names, shapes, checkBatchAxis, exceptionPrefix) {\n    if (checkBatchAxis === void 0) { checkBatchAxis = true; }\n    if (exceptionPrefix === void 0) { exceptionPrefix = ''; }\n    var arrays;\n    if (Array.isArray(data)) {\n        if (data.length !== names.length) {\n            throw new errors_1.ValueError(\"Error when checking model \" + exceptionPrefix + \": the Array of \" +\n                \"Tensors that you are passing to your model is not the size the \" +\n                (\"the model expected. Expected to see \" + names.length + \" Tensor(s),\") +\n                (\" but instead got \" + data.length + \" Tensors(s).\"));\n        }\n        arrays = data;\n    }\n    else {\n        if (names.length > 1) {\n            throw new errors_1.ValueError(\"The model expects \" + names.length + \" \" + exceptionPrefix + \" Tensors, \" +\n                \"but only received one Tensor. Found: array with shape \" +\n                (JSON.stringify(data.shape) + \".\"));\n        }\n        arrays = [data];\n    }\n    if (shapes != null) {\n        for (var i = 0; i < names.length; ++i) {\n            if (shapes[i] == null) {\n                continue;\n            }\n            var array = arrays[i];\n            if (array.shape.length !== shapes[i].length) {\n                throw new errors_1.ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" + names[i] + \" \" +\n                    (\"to have \" + shapes[i].length + \" dimension(s), but got array with \") +\n                    (\"shape \" + JSON.stringify(array.shape)));\n            }\n            for (var j = 0; j < shapes[i].length; ++j) {\n                if (j === 0 && !checkBatchAxis) {\n                    continue;\n                }\n                var dim = array.shape[j];\n                var refDim = shapes[i][j];\n                if (refDim != null) {\n                    if (refDim !== dim) {\n                        throw new errors_1.ValueError(\"Error when checking \" + exceptionPrefix + \": expected \" +\n                            (names[i] + \" to have shape \" + JSON.stringify(shapes[i]) + \" but \") +\n                            (\"got array with shape \" + JSON.stringify(array.shape) + \".\"));\n                    }\n                }\n            }\n        }\n    }\n}\nfunction collectMetrics(metrics, outputNames) {\n    if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {\n        return outputNames.map(function (name) { return []; });\n    }\n    if (Array.isArray(metrics)) {\n        return outputNames.map(function (name) { return metrics; });\n    }\n    else if (metrics != null) {\n        var nestedMetrics = [];\n        for (var _i = 0, outputNames_1 = outputNames; _i < outputNames_1.length; _i++) {\n            var name_2 = outputNames_1[_i];\n            var outputMetrics = metrics.hasOwnProperty(name_2) ? metrics[name_2] : [];\n            if (!Array.isArray(outputMetrics)) {\n                outputMetrics = [outputMetrics];\n            }\n            nestedMetrics.push(outputMetrics);\n        }\n        return nestedMetrics;\n    }\n    else {\n        throw new TypeError('Type of metrics argument not understood. Expected an Array or ' +\n            'Object, found: ' + metrics);\n    }\n}\nvar ModelLoggingVerbosity;\n(function (ModelLoggingVerbosity) {\n    ModelLoggingVerbosity[ModelLoggingVerbosity[\"SILENT\"] = 0] = \"SILENT\";\n    ModelLoggingVerbosity[ModelLoggingVerbosity[\"VERBOSE\"] = 1] = \"VERBOSE\";\n})(ModelLoggingVerbosity = exports.ModelLoggingVerbosity || (exports.ModelLoggingVerbosity = {}));\nvar Model = (function (_super) {\n    __extends(Model, _super);\n    function Model(config) {\n        return _super.call(this, config) || this;\n    }\n    Model.prototype.getClassName = function () {\n        return 'Model';\n    };\n    Model.prototype.compile = function (config) {\n        var _this = this;\n        if (config.loss == null) {\n            config.loss = [];\n        }\n        this.loss = config.loss;\n        if (typeof config.optimizer === 'string') {\n            this.optimizer = optimizers.getOptimizer(config.optimizer);\n        }\n        else {\n            if (!(config.optimizer instanceof tfjs_core_1.Optimizer)) {\n                throw new errors_1.ValueError(\"User-defined optimizer must be an instance of tf.Optimizer.\");\n            }\n            this.optimizer = config.optimizer;\n        }\n        var lossFunctions = [];\n        if (!Array.isArray(config.loss) && typeof config.loss !== 'string' &&\n            typeof config.loss !== 'function') {\n            config.loss = config.loss;\n            for (var name_3 in config.loss) {\n                if (this.outputNames.indexOf(name_3) === -1) {\n                    throw new errors_1.ValueError(\"Unknown entry in loss dictionary: \\\"\" + name_3 + \"\\\". Only expect the \" +\n                        (\"following keys: \" + this.outputNames));\n                }\n            }\n            for (var name_4 in this.outputNames) {\n                if (config.loss[name_4] == null) {\n                    console.warn(\"Output \\\"\" + name_4 + \"\\\" is missing from loss dictionary. We assume \" +\n                        \"this was done on purpose, and we will not be expecting data \" +\n                        (\"to be passed to \" + name_4 + \" during training\"));\n                }\n                lossFunctions.push(losses.get(config.loss[name_4]));\n            }\n        }\n        else if (Array.isArray(config.loss)) {\n            if (config.loss.length !== this.outputs.length) {\n                throw new errors_1.ValueError(\"When passing an Array as loss, it should have one entry per \" +\n                    (\"model output. The model has \" + this.outputs.length + \" output(s), \") +\n                    (\"but you passed loss=\" + config.loss + \".\"));\n            }\n            var theLosses = config.loss;\n            lossFunctions = theLosses.map(function (l) { return losses.get(l); });\n        }\n        else {\n            var lossFunction_1 = losses.get(config.loss);\n            this.outputs.map(function (layer) {\n                lossFunctions.push(lossFunction_1);\n            });\n        }\n        this.lossFunctions = lossFunctions;\n        this.feedOutputNames = [];\n        this.feedOutputShapes = [];\n        this.feedLossFns = [];\n        for (var i = 0; i < this.outputs.length; ++i) {\n            var shape = this.internalOutputShapes[i];\n            var name_5 = this.outputNames[i];\n            this.feedOutputNames.push(name_5);\n            this.feedOutputShapes.push(shape);\n            this.feedLossFns.push(this.lossFunctions[i]);\n        }\n        var skipTargetIndices = [];\n        this.metrics = config.metrics;\n        this.metricsNames = ['loss'];\n        this.metricsTensors = [];\n        K.nameScope('loss', function () {\n            for (var i = 0; i < _this.outputs.length; ++i) {\n                if (skipTargetIndices.indexOf(i) !== -1) {\n                    continue;\n                }\n                var weightedLoss = _this.lossFunctions[i];\n                if (_this.outputs.length > 1) {\n                    _this.metricsTensors.push([weightedLoss, i]);\n                    _this.metricsNames.push(_this.outputNames[i] + '_loss');\n                }\n            }\n        });\n        var nestedMetrics = collectMetrics(config.metrics, this.outputNames);\n        var appendMetric = function (outputIndex, metricName, metricTensor) {\n            if (_this.outputNames.length > 1) {\n                metricName = _this.outputNames[outputIndex] + '_' + metricName;\n            }\n            _this.metricsNames.push(metricName);\n            _this.metricsTensors.push([metricTensor, outputIndex]);\n        };\n        K.nameScope('metric', function () {\n            var _loop_1 = function (i) {\n                if (skipTargetIndices.indexOf(i) !== -1) {\n                    return \"continue\";\n                }\n                var outputMetrics = nestedMetrics[i];\n                var handleMetrics = function (metrics) {\n                    var metricNamePrefix = '';\n                    var metricName;\n                    var accFn;\n                    var weightedMetricFn;\n                    var _loop_2 = function (metric) {\n                        if (['accuracy', 'acc', 'crossentropy', 'ce'].indexOf(metric) !==\n                            -1) {\n                            var outputShape = _this.internalOutputShapes[i];\n                            if (outputShape[outputShape.length - 1] === 1 ||\n                                _this.lossFunctions[i] === losses.binaryCrossentropy) {\n                                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.binaryAccuracy;\n                                }\n                                else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.binaryCrossentropy;\n                                }\n                            }\n                            else if (_this.lossFunctions[i] ===\n                                losses.sparseCategoricalCrossentropy) {\n                                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.sparseCategoricalAccuracy;\n                                }\n                                else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.sparseCategoricalCrossentropy;\n                                }\n                            }\n                            else {\n                                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.categoricalAccuracy;\n                                }\n                                else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.categoricalCrossentropy;\n                                }\n                            }\n                            var suffix = void 0;\n                            if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                suffix = 'acc';\n                            }\n                            else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                suffix = 'ce';\n                            }\n                            weightedMetricFn = accFn;\n                            metricName = metricNamePrefix + suffix;\n                        }\n                        else {\n                            var metricFn = Metrics.get(metric);\n                            weightedMetricFn = metricFn;\n                            metricName = metricNamePrefix + metric;\n                        }\n                        var metricResult;\n                        K.nameScope(metricName, function () {\n                            metricResult = weightedMetricFn;\n                        });\n                        appendMetric(i, metricName, metricResult);\n                    };\n                    for (var _i = 0, metrics_1 = metrics; _i < metrics_1.length; _i++) {\n                        var metric = metrics_1[_i];\n                        _loop_2(metric);\n                    }\n                };\n                handleMetrics(outputMetrics);\n            };\n            for (var i = 0; i < _this.outputs.length; ++i) {\n                _loop_1(i);\n            }\n        });\n        this.collectedTrainableWeights = this.trainableWeights;\n    };\n    Model.prototype.checkTrainableWeightsConsistency = function () {\n        if (this.collectedTrainableWeights == null) {\n            return;\n        }\n        if (this.trainableWeights.length !==\n            this.collectedTrainableWeights.length) {\n            console.warn('Discrepancy between trainableweights and collected trainable ' +\n                'weights. Did you set `model.trainable` without calling ' +\n                '`model.compile()` afterwards?');\n        }\n    };\n    Model.prototype.evaluate = function (x, y, config) {\n        if (config === void 0) { config = {}; }\n        var batchSize = config.batchSize == null ? 32 : config.batchSize;\n        var standardizedOuts = this.standardizeUserData(x, y, true, batchSize);\n        var ins = standardizedOuts[0].concat(standardizedOuts[1]);\n        this.makeTestFunction();\n        var f = this.testFunction;\n        var testOuts = this.testLoop(f, ins, batchSize, config.verbose, config.steps);\n        return generic_utils_1.singletonOrArray(testOuts);\n    };\n    Model.prototype.checkNumSamples = function (ins, batchSize, steps, stepsName) {\n        if (stepsName === void 0) { stepsName = 'steps'; }\n        var numSamples;\n        if (steps != null) {\n            numSamples = null;\n            if (batchSize != null) {\n                throw new errors_1.ValueError(\"If \" + stepsName + \" is set, batchSize must be null or undefined.\" +\n                    (\"Got batchSize = \" + batchSize));\n            }\n        }\n        else if (ins != null) {\n            if (Array.isArray(ins)) {\n                numSamples = ins[0].shape[0];\n            }\n            else {\n                numSamples = ins.shape[0];\n            }\n        }\n        else {\n            throw new errors_1.ValueError(\"Either the input data should have a defined shape, or \" +\n                (stepsName + \" shoud be specified.\"));\n        }\n        return numSamples;\n    };\n    Model.prototype.predictLoop = function (ins, batchSize, verbose) {\n        var _this = this;\n        if (batchSize === void 0) { batchSize = 32; }\n        if (verbose === void 0) { verbose = false; }\n        var numSamples = this.checkNumSamples(ins);\n        if (verbose) {\n            throw new errors_1.NotImplementedError('Verbose predictLoop() is not implemented yet.');\n        }\n        var batches = makeBatches(numSamples, batchSize);\n        var outs = [];\n        var _loop_3 = function (batchIndex) {\n            var batchOuts = tfc.tidy(function () {\n                var batchStart = batches[batchIndex][0];\n                var batchEnd = batches[batchIndex][1];\n                var insBatch = sliceArrays(ins, batchStart, batchEnd);\n                var feeds = [];\n                if (Array.isArray(insBatch)) {\n                    for (var i = 0; i < insBatch.length; ++i) {\n                        feeds.push({ key: _this.inputs[i], value: insBatch[i] });\n                    }\n                }\n                else {\n                    feeds.push({ key: _this.inputs[0], value: insBatch });\n                }\n                var feedDict = new executor_1.FeedDict(feeds);\n                return executor_1.execute(_this.outputs, feedDict);\n            });\n            if (batchIndex === 0) {\n                for (var _i = 0, batchOuts_1 = batchOuts; _i < batchOuts_1.length; _i++) {\n                    var batchOut = batchOuts_1[_i];\n                    outs.push(batchOut);\n                }\n            }\n            else {\n                for (var i = 0; i < batchOuts.length; ++i) {\n                    outs[i] = K.concatAlongFirstAxis(outs[i], batchOuts[i]);\n                }\n            }\n        };\n        for (var batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n            _loop_3(batchIndex);\n        }\n        return generic_utils_1.singletonOrArray(outs);\n    };\n    Model.prototype.predict = function (x, config) {\n        if (config === void 0) { config = {}; }\n        checkInputData(x, this.inputNames, this.feedInputShapes, false);\n        var batchSize = config.batchSize == null ? 32 : config.batchSize;\n        return this.predictLoop(x, batchSize);\n    };\n    Model.prototype.predictOnBatch = function (x) {\n        checkInputData(x, this.inputNames, this.feedInputShapes, true);\n        return this.predictLoop(x, x.shape[0]);\n    };\n    Model.prototype.standardizeUserData = function (x, y, checkBatchAxis, batchSize) {\n        if (checkBatchAxis === void 0) { checkBatchAxis = true; }\n        if (this.optimizer == null) {\n            throw new errors_1.RuntimeError('You must compile a model before training/testing. Use ' +\n                'Model.compile(modelCompileConfig).');\n        }\n        var outputShapes = [];\n        for (var i = 0; i < this.feedOutputShapes.length; ++i) {\n            var outputShape = this.feedOutputShapes[i];\n            var lossFn = this.feedLossFns[i];\n            if (lossFn === losses.sparseCategoricalCrossentropy) {\n                outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));\n            }\n            else {\n                outputShapes.push(outputShape);\n            }\n        }\n        x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, 'input');\n        y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, 'target');\n        checkArrayLengths(x, y, null);\n        checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);\n        if (this.stateful && batchSize != null && batchSize > 0) {\n            if (x[0].shape[0] % batchSize !== 0) {\n                throw new errors_1.ValueError(\"In a stateful network, you should only pass inputs with a \" +\n                    \"number of samples that is divisible by the batch size \" +\n                    (batchSize + \". Found: \" + x[0].shape[0] + \" sample(s).\"));\n            }\n        }\n        return [x, y, null];\n    };\n    Model.prototype.fitLoop = function (f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n        if (initialEpoch === void 0) { initialEpoch = 0; }\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            var doValidation, numTrainSamples, indexArray, callbackList, _loop_4, epoch;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (batchSize == null) {\n                            batchSize = 32;\n                        }\n                        if (epochs == null) {\n                            epochs = 100;\n                        }\n                        if (shuffle == null) {\n                            shuffle = true;\n                        }\n                        if (initialEpoch == null) {\n                            initialEpoch = 0;\n                        }\n                        doValidation = false;\n                        if (valF != null && valIns != null) {\n                            doValidation = true;\n                        }\n                        if (validationSteps != null) {\n                            doValidation = true;\n                            if (stepsPerEpoch == null) {\n                                throw new errors_1.ValueError('Can only use `validationSteps` when doing step-wise training, ' +\n                                    'i.e., `stepsPerEpoch` must be set.');\n                            }\n                        }\n                        numTrainSamples = this.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n                        if (numTrainSamples != null) {\n                            indexArray = math_utils_1.range(0, numTrainSamples);\n                        }\n                        this.history = new callbacks_1.History();\n                        if (callbacks == null) {\n                            callbacks = [new callbacks_1.BaseLogger()];\n                        }\n                        else {\n                            callbacks = [new callbacks_1.BaseLogger()].concat(callbacks);\n                        }\n                        callbacks = callbacks.concat([this.history]);\n                        if (verbose > 0) {\n                            throw new errors_1.NotImplementedError('Verbose mode is not implemented yet.');\n                        }\n                        callbackList = new callbacks_1.CallbackList(callbacks);\n                        callbackList.setModel(this);\n                        callbackList.setParams({\n                            epochs: epochs,\n                            steps: stepsPerEpoch,\n                            verbose: verbose,\n                            doValidation: doValidation,\n                            metrics: callbackMetrics,\n                        });\n                        return [4, callbackList.onTrainBegin()];\n                    case 1:\n                        _a.sent();\n                        _loop_4 = function (epoch) {\n                            var epochLogs, epochIndexArray1D_1, batches_1, _loop_5, batchIndex;\n                            return __generator(this, function (_a) {\n                                switch (_a.label) {\n                                    case 0: return [4, callbackList.onEpochBegin(epoch)];\n                                    case 1:\n                                        _a.sent();\n                                        epochLogs = {};\n                                        if (!(stepsPerEpoch != null)) return [3, 2];\n                                        throw new errors_1.NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n                                    case 2:\n                                        if (shuffle === 'batch') {\n                                            throw new errors_1.NotImplementedError('batch shuffling is not implemneted yet');\n                                        }\n                                        else if (shuffle) {\n                                            tfjs_core_1.util.shuffle(indexArray);\n                                        }\n                                        epochIndexArray1D_1 = tfjs_core_1.tensor1d(indexArray);\n                                        batches_1 = makeBatches(numTrainSamples, batchSize);\n                                        _loop_5 = function (batchIndex) {\n                                            var batchLogs;\n                                            return __generator(this, function (_a) {\n                                                switch (_a.label) {\n                                                    case 0:\n                                                        batchLogs = {};\n                                                        return [4, callbackList.onBatchBegin(batchIndex, batchLogs)];\n                                                    case 1:\n                                                        _a.sent();\n                                                        tfc.tidy(function () {\n                                                            var batchStart = batches_1[batchIndex][0];\n                                                            var batchEnd = batches_1[batchIndex][1];\n                                                            var batchIds = K.sliceAlongFirstAxis(epochIndexArray1D_1, batchStart, batchEnd - batchStart);\n                                                            batchLogs['batch'] = batchIndex;\n                                                            batchLogs['size'] = batchEnd - batchStart;\n                                                            var insBatch = sliceArraysByIndices(ins, batchIds);\n                                                            var outs = f(insBatch);\n                                                            for (var i = 0; i < outLabels.length; ++i) {\n                                                                var label = outLabels[i];\n                                                                var out = outs[i];\n                                                                batchLogs[label] = out;\n                                                                K.keep(out);\n                                                            }\n                                                            if (batchIndex === batches_1.length - 1) {\n                                                                if (doValidation) {\n                                                                    var valOuts = _this.testLoop(valF, valIns, batchSize);\n                                                                    for (var i = 0; i < outLabels.length; ++i) {\n                                                                        var label = outLabels[i];\n                                                                        var out = valOuts[i];\n                                                                        K.keep(out);\n                                                                        epochLogs['val_' + label] = out;\n                                                                    }\n                                                                }\n                                                            }\n                                                        });\n                                                        return [4, callbackList.onBatchEnd(batchIndex, batchLogs)];\n                                                    case 2:\n                                                        _a.sent();\n                                                        callbacks_1.disposeTensorsInLogs(batchLogs);\n                                                        return [2];\n                                                }\n                                            });\n                                        };\n                                        batchIndex = 0;\n                                        _a.label = 3;\n                                    case 3:\n                                        if (!(batchIndex < batches_1.length)) return [3, 6];\n                                        return [5, _loop_5(batchIndex)];\n                                    case 4:\n                                        _a.sent();\n                                        _a.label = 5;\n                                    case 5:\n                                        ++batchIndex;\n                                        return [3, 3];\n                                    case 6:\n                                        epochIndexArray1D_1.dispose();\n                                        _a.label = 7;\n                                    case 7: return [4, callbackList.onEpochEnd(epoch, epochLogs)];\n                                    case 8:\n                                        _a.sent();\n                                        return [2];\n                                }\n                            });\n                        };\n                        epoch = initialEpoch;\n                        _a.label = 2;\n                    case 2:\n                        if (!(epoch < epochs)) return [3, 5];\n                        return [5, _loop_4(epoch)];\n                    case 3:\n                        _a.sent();\n                        _a.label = 4;\n                    case 4:\n                        ++epoch;\n                        return [3, 2];\n                    case 5: return [4, callbackList.onTrainEnd()];\n                    case 6:\n                        _a.sent();\n                        return [4, this.history.syncData()];\n                    case 7:\n                        _a.sent();\n                        return [2, this.history];\n                }\n            });\n        });\n    };\n    Model.prototype.testLoop = function (f, ins, batchSize, verbose, steps) {\n        if (verbose === void 0) { verbose = 0; }\n        var numSamples = this.checkNumSamples(ins, batchSize, steps, 'steps');\n        var outs = [];\n        if (verbose === 1) {\n            throw new errors_1.NotImplementedError('Verbose mode is not implemented yet.');\n        }\n        if (steps != null) {\n            throw new errors_1.NotImplementedError('steps mode in testLoop() is not implemented yet');\n        }\n        else {\n            var batches = makeBatches(numSamples, batchSize);\n            var indexArray = tfjs_core_1.tensor1d(math_utils_1.range(0, numSamples));\n            for (var batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                var batchStart = batches[batchIndex][0];\n                var batchEnd = batches[batchIndex][1];\n                var batchIds = K.sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart);\n                var insBatch = sliceArraysByIndices(ins, batchIds);\n                var batchOuts = f(insBatch);\n                if (batchIndex === 0) {\n                    for (var i = 0; i < batchOuts.length; ++i) {\n                        outs.push(K.getScalar(0));\n                    }\n                }\n                for (var i = 0; i < batchOuts.length; ++i) {\n                    var batchOut = batchOuts[i];\n                    outs[i] =\n                        K.add(outs[i], K.scalarTimesArray(K.getScalar(batchEnd - batchStart), batchOut));\n                }\n            }\n            for (var i = 0; i < outs.length; ++i) {\n                outs[i] = K.divide(outs[i], K.getScalar(numSamples));\n            }\n        }\n        return outs;\n    };\n    Model.prototype.getDedupedMetricsNames = function () {\n        var outLabels = this.metricsNames;\n        var dedupedOutLabels = [];\n        for (var i = 0; i < outLabels.length; ++i) {\n            var label = outLabels[i];\n            var newLabel = label;\n            if (generic_utils_1.count(outLabels, label) > 1) {\n                var dupIndex = generic_utils_1.count(outLabels.slice(0, i), label);\n                newLabel += \"_\" + dupIndex;\n            }\n            dedupedOutLabels.push(newLabel);\n        }\n        return dedupedOutLabels;\n    };\n    Model.prototype.makeTestFunction = function () {\n        var _this = this;\n        this.testFunction = function (data) {\n            return tfc.tidy(function () {\n                var valOutputs = [];\n                var totalLoss;\n                var inputs = data.slice(0, _this.inputs.length);\n                var targets = data.slice(_this.inputs.length, _this.inputs.length + _this.outputs.length);\n                var feeds = [];\n                for (var i = 0; i < _this.inputs.length; ++i) {\n                    feeds.push({ key: _this.inputs[i], value: inputs[i] });\n                }\n                var feedDict = new executor_1.FeedDict(feeds);\n                var outputs = executor_1.execute(_this.outputs, feedDict);\n                for (var i = 0; i < _this.lossFunctions.length; ++i) {\n                    var lossFunction = _this.lossFunctions[i];\n                    var loss = K.mean(lossFunction(targets[i], outputs[i]));\n                    if (i === 0) {\n                        totalLoss = loss;\n                    }\n                    else {\n                        totalLoss = K.add(totalLoss, loss);\n                    }\n                    valOutputs.push(totalLoss);\n                }\n                for (var i = 0; i < _this.metricsTensors.length; ++i) {\n                    var metric = _this.metricsTensors[i][0];\n                    var outputIndex = _this.metricsTensors[i][1];\n                    var meanMetric = K.mean(metric(targets[outputIndex], outputs[outputIndex]));\n                    valOutputs.push(meanMetric);\n                }\n                return valOutputs;\n            });\n        };\n    };\n    Model.prototype.fit = function (x, y, config) {\n        if (config === void 0) { config = {}; }\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            var batchSize, standardizedOuts, inputs, targets, doValidation, valX, valY, valIns, valStandardized, splitAt, originalBatchSize, ins, trainFunction, outLabels, valFunction, callbackMetrics, callbacks;\n            return __generator(this, function (_a) {\n                batchSize = config.batchSize == null ? 32 : config.batchSize;\n                standardizedOuts = this.standardizeUserData(x, y, false, batchSize);\n                inputs = standardizedOuts[0];\n                targets = standardizedOuts[1];\n                doValidation = false;\n                if (config.validationData != null && config.validationData.length > 0) {\n                    doValidation = true;\n                    if (config.validationData.length === 2) {\n                        valX = config.validationData[0];\n                        valY = config.validationData[1];\n                    }\n                    else if (config.validationData.length === 3) {\n                        throw new errors_1.NotImplementedError('validationData including sample weights is not supported yet.');\n                    }\n                    else {\n                        throw new errors_1.ValueError(\"When passing validation data, it must contain 2 (valX, valY) \" +\n                            \"or 3 (valX, valY, valSampleWeight) items; \" +\n                            (config.validationData + \" is invalid.\"));\n                    }\n                    valStandardized = this.standardizeUserData(valX, valY, true, batchSize);\n                    valX = valStandardized[0];\n                    valY = valStandardized[1];\n                    valIns = valX.concat(valY);\n                }\n                else if (config.validationSplit != null && config.validationSplit > 0 &&\n                    config.validationSplit < 1) {\n                    doValidation = true;\n                    splitAt = Math.floor(inputs[0].shape[0] * (1 - config.validationSplit));\n                    originalBatchSize = inputs[0].shape[0];\n                    valX = sliceArrays(inputs, splitAt, originalBatchSize);\n                    inputs = sliceArrays(inputs, 0, splitAt);\n                    valY = sliceArrays(targets, splitAt, originalBatchSize);\n                    targets = sliceArrays(targets, 0, splitAt);\n                    valIns = valX.concat(valY);\n                }\n                else if (config.validationSteps != null) {\n                    doValidation = true;\n                }\n                ins = inputs.concat(targets);\n                this.checkTrainableWeightsConsistency();\n                trainFunction = function (data) {\n                    var losses = [];\n                    var lossValues = [];\n                    var inputs = data.slice(0, _this.inputs.length);\n                    var targets = data.slice(_this.inputs.length, _this.inputs.length + _this.outputs.length);\n                    var metricsValues = [];\n                    var totalLossFunction = function () {\n                        var feeds = [];\n                        for (var i = 0; i < _this.inputs.length; ++i) {\n                            feeds.push({ key: _this.inputs[i], value: inputs[i] });\n                        }\n                        var feedDict = new executor_1.FeedDict(feeds);\n                        var outputs = executor_1.execute(_this.outputs, feedDict, { 'training': true });\n                        var totalLoss;\n                        for (var i = 0; i < _this.lossFunctions.length; ++i) {\n                            var lossFunction = _this.lossFunctions[i];\n                            var loss = lossFunction(targets[i], outputs[i]);\n                            losses.push(loss);\n                            var meanLoss = K.mean(loss);\n                            lossValues.push(meanLoss);\n                            if (i === 0) {\n                                totalLoss = loss;\n                            }\n                            else {\n                                totalLoss = K.add(totalLoss, loss);\n                            }\n                        }\n                        for (var i = 0; i < _this.metricsTensors.length; ++i) {\n                            var metric = _this.metricsTensors[i][0];\n                            var outputIndex = _this.metricsTensors[i][1];\n                            var meanMetric = K.mean(metric(targets[outputIndex], outputs[outputIndex]));\n                            K.keep(meanMetric);\n                            metricsValues.push(meanMetric);\n                        }\n                        totalLoss = K.mean(totalLoss);\n                        _this.calculateLosses().forEach(function (regularizerLoss) {\n                            totalLoss = K.add(totalLoss, regularizerLoss);\n                        });\n                        return totalLoss;\n                    };\n                    var variables = _this.collectedTrainableWeights.map(function (param) { return param.read(); });\n                    var returnCost = true;\n                    var totalLossValue = _this.optimizer.minimize(totalLossFunction, returnCost, variables);\n                    return [totalLossValue].concat(metricsValues);\n                };\n                outLabels = this.getDedupedMetricsNames();\n                if (doValidation) {\n                    this.makeTestFunction();\n                    valFunction = this.testFunction;\n                    callbackMetrics =\n                        outLabels.slice().concat(outLabels.map(function (n) { return 'val_' + n; }));\n                }\n                else {\n                    valFunction = null;\n                    valIns = [];\n                    callbackMetrics = outLabels.slice();\n                }\n                callbacks = callbacks_1.standardizeCallbacks(config.callbacks);\n                return [2, this.fitLoop(trainFunction, ins, outLabels, batchSize, config.epochs, config.verbose, callbacks, valFunction, valIns, config.shuffle, callbackMetrics, null, null, null)];\n            });\n        });\n    };\n    __decorate([\n        tfjs_core_1.doc({ heading: 'Models', subheading: 'Classes', configParamIndices: [0] })\n    ], Model.prototype, \"compile\", null);\n    __decorate([\n        tfjs_core_1.doc({ heading: 'Models', subheading: 'Classes', configParamIndices: [2] })\n    ], Model.prototype, \"evaluate\", null);\n    __decorate([\n        tfjs_core_1.doc({ heading: 'Models', subheading: 'Classes', configParamIndices: [1] })\n    ], Model.prototype, \"predict\", null);\n    __decorate([\n        tfjs_core_1.doc({ heading: 'Models', subheading: 'Classes' })\n    ], Model.prototype, \"predictOnBatch\", null);\n    __decorate([\n        tfjs_core_1.doc({ heading: 'Models', subheading: 'Classes', configParamIndices: [2] })\n    ], Model.prototype, \"fit\", null);\n    Model = __decorate([\n        tfjs_core_1.doc({ heading: 'Models', subheading: 'Classes' })\n    ], Model);\n    return Model;\n}(topology_1.Container));\nexports.Model = Model;\ngeneric_utils_1.ClassNameMap.register('Model', Model);\n"},"hash":"5eae51d4fe8f22257c3f0d0eb218b16c","cacheData":{"env":{}}}