{"dependencies":[{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\package.json","includedInParent":true,"mtime":1528200878026},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\.babelrc","includedInParent":true,"mtime":1528197961732},{"name":"C:\\Users\\qison\\Google Drive\\tfjs_vae\\nodejs_version\\node_modules\\@tensorflow\\tfjs-layers\\package.json","includedInParent":true,"mtime":1524501157000},{"name":"@tensorflow/tfjs-core","loc":{"line":19,"column":26}},{"name":"../activations","loc":{"line":20,"column":28}},{"name":"../backend/tfjs_backend","loc":{"line":21,"column":16}},{"name":"../constraints","loc":{"line":22,"column":28}},{"name":"../engine/topology","loc":{"line":24,"column":25}},{"name":"../errors","loc":{"line":25,"column":23}},{"name":"../initializers","loc":{"line":26,"column":29}},{"name":"../regularizers","loc":{"line":27,"column":29}},{"name":"../types","loc":{"line":28,"column":22}},{"name":"../utils/generic_utils","loc":{"line":29,"column":28}},{"name":"../utils/math_utils","loc":{"line":30,"column":25}},{"name":"./serialization","loc":{"line":31,"column":30}}],"generated":{"js":"\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar activations_1 = require(\"../activations\");\nvar K = require(\"../backend/tfjs_backend\");\nvar constraints_1 = require(\"../constraints\");\nvar topology_1 = require(\"../engine/topology\");\nvar topology_2 = require(\"../engine/topology\");\nvar errors_1 = require(\"../errors\");\nvar initializers_1 = require(\"../initializers\");\nvar regularizers_1 = require(\"../regularizers\");\nvar types_1 = require(\"../types\");\nvar generic_utils = require(\"../utils/generic_utils\");\nvar math_utils = require(\"../utils/math_utils\");\nvar serialization_1 = require(\"./serialization\");\nvar RNN = (function (_super) {\n    __extends(RNN, _super);\n    function RNN(config) {\n        var _this = _super.call(this, config) || this;\n        var cell;\n        if (config.cell == null) {\n            throw new errors_1.ValueError('cell property is missing for the constructor of RNN.');\n        }\n        else if (Array.isArray(config.cell)) {\n            cell = new StackedRNNCells({ cells: config.cell });\n        }\n        else {\n            cell = config.cell;\n        }\n        if (cell.stateSize == null) {\n            throw new errors_1.ValueError('The RNN cell should have an attribute `stateSize` (tuple of ' +\n                'integers, one integer per RNN state).');\n        }\n        _this.cell = cell;\n        _this.returnSequences =\n            config.returnSequences == null ? false : config.returnSequences;\n        _this.returnState = config.returnState == null ? false : config.returnState;\n        _this.goBackwards = config.goBackwards == null ? false : config.goBackwards;\n        _this._stateful = config.stateful == null ? false : config.stateful;\n        _this.unroll = config.unroll == null ? false : config.unroll;\n        _this.supportsMasking = true;\n        _this.inputSpec = [new topology_1.InputSpec({ ndim: 3 })];\n        _this.stateSpec = null;\n        _this.states = null;\n        _this.numConstants = null;\n        return _this;\n    }\n    RNN.prototype.getStates = function () {\n        if (this.states == null) {\n            var numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n            return math_utils.range(0, numStates).map(function (x) { return null; });\n        }\n        else {\n            return this.states;\n        }\n    };\n    RNN.prototype.setStates = function (states) {\n        this.states = states;\n    };\n    RNN.prototype.computeOutputShape = function (inputShape) {\n        if (generic_utils.isArrayOfShapes(inputShape)) {\n            inputShape = inputShape[0];\n        }\n        inputShape = inputShape;\n        var stateSize = this.cell.stateSize;\n        if (!Array.isArray(stateSize)) {\n            stateSize = [stateSize];\n        }\n        var outputDim = stateSize[0];\n        var outputShape;\n        if (this.returnSequences) {\n            outputShape = [inputShape[0], inputShape[1], outputDim];\n        }\n        else {\n            outputShape = [inputShape[0], outputDim];\n        }\n        if (this.returnState) {\n            var stateShape = [];\n            for (var _i = 0, stateSize_1 = stateSize; _i < stateSize_1.length; _i++) {\n                var dim = stateSize_1[_i];\n                stateShape.push([inputShape[0], dim]);\n            }\n            return [outputShape].concat(stateShape);\n        }\n        else {\n            return outputShape;\n        }\n    };\n    RNN.prototype.computeMask = function (inputs, mask) {\n        throw new errors_1.NotImplementedError('computeMask has not been implemented for RNN yet');\n    };\n    RNN.prototype.build = function (inputShape) {\n        var constantShape = null;\n        if (this.numConstants != null) {\n            throw new errors_1.NotImplementedError('Constants support is not implemented in RNN yet.');\n        }\n        if (generic_utils.isArrayOfShapes(inputShape)) {\n            inputShape = inputShape[0];\n        }\n        inputShape = inputShape;\n        var batchSize = this.stateful ? inputShape[0] : null;\n        var inputDim = inputShape[inputShape.length - 1];\n        this.inputSpec[0] = new topology_1.InputSpec({ shape: [batchSize, null, inputDim] });\n        var stepInputShape = [inputShape[0]].concat(inputShape.slice(2));\n        if (constantShape != null) {\n            throw new errors_1.NotImplementedError('Constants support is not implemented in RNN yet.');\n        }\n        else {\n            this.cell.build(stepInputShape);\n        }\n        var stateSize;\n        if (Array.isArray(this.cell.stateSize)) {\n            stateSize = this.cell.stateSize;\n        }\n        else {\n            stateSize = [this.cell.stateSize];\n        }\n        if (this.stateSpec != null) {\n            if (!tfjs_core_1.util.arraysEqual(this.stateSpec.map(function (spec) { return spec.shape[spec.shape.length - 1]; }), stateSize)) {\n                throw new errors_1.ValueError(\"An initialState was passed that is not compatible with \" +\n                    (\"cell.stateSize. Received stateSpec=\" + this.stateSpec + \"; \") +\n                    (\"However cell.stateSize is \" + this.cell.stateSize));\n            }\n        }\n        else {\n            this.stateSpec =\n                stateSize.map(function (dim) { return new topology_1.InputSpec({ shape: [null, dim] }); });\n        }\n        if (this.stateful) {\n            throw new errors_1.NotImplementedError('stateful RNN layer is not implemented yet');\n        }\n    };\n    RNN.prototype.resetStates = function (states) {\n        if (!this.stateful) {\n            throw new errors_1.AttributeError('Cannot call resetState() on an RNN Layer that is not stateful.');\n        }\n        var batchSize = this.inputSpec[0].shape[0];\n        if (batchSize == null) {\n            throw new errors_1.ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' +\n                'the batch size of your input tensors: \\n' +\n                '- If using a Sequential model, specify the batch size by passing ' +\n                'a `batchInputShape` option to your first layer.\\n' +\n                '- If using the functional API, specify the batch size by ' +\n                'passing a `batchShape` option to your Input layer.');\n        }\n        if (this.states == null) {\n            if (Array.isArray(this.cell.stateSize)) {\n                this.states = this.cell.stateSize.map(function (dim) { return K.zeros([batchSize, dim]); });\n            }\n            else {\n                this.states = [K.zeros([batchSize, this.cell.stateSize])];\n            }\n        }\n        else if (states == null) {\n            if (Array.isArray(this.cell.stateSize)) {\n                this.states = this.cell.stateSize.map(function (dim) { return K.zeros([batchSize, dim]); });\n            }\n            else {\n                this.states[0] = K.zeros([batchSize, this.cell.stateSize]);\n            }\n        }\n        else {\n            if (!Array.isArray(states)) {\n                states = [states];\n            }\n            if (states.length !== this.states.length) {\n                throw new errors_1.ValueError(\"Layer \" + this.name + \" expects \" + this.states.length + \" state(s), \" +\n                    (\"but it received \" + states.length + \" state value(s). Input \") +\n                    (\"received: \" + states));\n            }\n            for (var index = 0; index < this.states.length; ++index) {\n                var value = states[index];\n                var dim = Array.isArray(this.cell.stateSize) ?\n                    this.cell.stateSize[index] :\n                    this.cell.stateSize;\n                var expectedShape = [batchSize, dim];\n                if (!tfjs_core_1.util.arraysEqual(value.shape, expectedShape)) {\n                    throw new errors_1.ValueError(\"State \" + index + \" is incompatible with layer \" + this.name + \": \" +\n                        (\"expected shape=\" + expectedShape + \", received shape=\" + value.shape));\n                }\n                this.states[index] = value;\n            }\n        }\n    };\n    RNN.prototype.standardizeArgs = function (inputs, initialState, constants) {\n        if (Array.isArray(inputs)) {\n            if (initialState != null || constants != null) {\n                throw new errors_1.ValueError('When inputs is an array, neither initialState or constants ' +\n                    'should be provided');\n            }\n            if (this.numConstants != null) {\n                constants =\n                    inputs.slice(inputs.length - this.numConstants, inputs.length);\n                inputs = inputs.slice(0, inputs.length - this.numConstants);\n            }\n            if (inputs.length > 1) {\n                initialState = inputs.slice(1, inputs.length);\n            }\n            inputs = inputs[0];\n        }\n        function toListOrNull(x) {\n            if (x == null || Array.isArray(x)) {\n                return x;\n            }\n            else {\n                return [x];\n            }\n        }\n        initialState = toListOrNull(initialState);\n        constants = toListOrNull(constants);\n        return { inputs: inputs, initialState: initialState, constants: constants };\n    };\n    RNN.prototype.apply = function (inputs, kwargs) {\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        var constants = kwargs == null ? null : kwargs['constants'];\n        if (kwargs == null) {\n            kwargs = {};\n        }\n        var standardized = this.standardizeArgs(inputs, initialState, constants);\n        inputs = standardized.inputs;\n        initialState = standardized.initialState;\n        constants = standardized.constants;\n        var additionalInputs = [];\n        var additionalSpecs = [];\n        if (initialState != null) {\n            kwargs['initialState'] = initialState;\n            additionalInputs = additionalInputs.concat(initialState);\n            this.stateSpec = [];\n            for (var _i = 0, initialState_1 = initialState; _i < initialState_1.length; _i++) {\n                var state = initialState_1[_i];\n                this.stateSpec.push(new topology_1.InputSpec({ shape: state.shape }));\n            }\n            additionalSpecs = additionalSpecs.concat(this.stateSpec);\n        }\n        if (constants != null) {\n            kwargs['constants'] = constants;\n            additionalInputs = additionalInputs.concat(constants);\n            this.numConstants = constants.length;\n        }\n        var isTensor = additionalInputs[0] instanceof types_1.SymbolicTensor;\n        if (isTensor) {\n            var fullInput = [inputs].concat(additionalInputs);\n            var fullInputSpec = this.inputSpec.concat(additionalSpecs);\n            var originalInputSpec = this.inputSpec;\n            this.inputSpec = fullInputSpec;\n            var output = _super.prototype.apply.call(this, fullInput, kwargs);\n            this.inputSpec = originalInputSpec;\n            return output;\n        }\n        else {\n            return _super.prototype.apply.call(this, inputs, kwargs);\n        }\n    };\n    RNN.prototype.call = function (inputs, kwargs) {\n        var _this = this;\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        inputs = generic_utils.getExactlyOneTensor(inputs);\n        if (initialState == null) {\n            if (this.stateful) {\n                throw new errors_1.NotImplementedError('stateful RNN layer is not implemented yet.');\n            }\n            else {\n                initialState = this.getInitialState(inputs);\n            }\n        }\n        if (mask != null) {\n            throw new errors_1.NotImplementedError('Masking is not implemented for RNN yet');\n        }\n        var numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;\n        if (initialState.length !== numStates) {\n            throw new errors_1.ValueError(\"RNN Layer has \" + numStates + \" state(s) but was passed \" +\n                (initialState.length + \" initial state(s).\"));\n        }\n        var inputShape = inputs.shape;\n        var timesteps = inputShape[1];\n        if (this.unroll) {\n            console.warn('Ignoring unroll = true for RNN layer, due to imperative backend.');\n        }\n        var cellCallKwargs = { training: training };\n        var step = function (inputs, states) {\n            var outputs = _this.cell.call([inputs].concat(states), cellCallKwargs);\n            return [outputs[0], outputs.slice(1)];\n        };\n        var rnnOutputs = K.rnn(step, inputs, initialState, this.goBackwards, null, null, this.unroll, timesteps);\n        var lastOutput = rnnOutputs[0];\n        var outputs = rnnOutputs[1];\n        var states = rnnOutputs[2];\n        if (this.stateful) {\n            throw new errors_1.NotImplementedError('stateful RNN layer is not implemented yet');\n        }\n        var output = this.returnSequences ? outputs : lastOutput;\n        if (this.returnState) {\n            return [output].concat(states);\n        }\n        else {\n            return output;\n        }\n    };\n    RNN.prototype.getInitialState = function (inputs) {\n        var initialState = K.zeros(inputs.shape);\n        initialState = K.sum(initialState, [1, 2]);\n        initialState = K.expandDims(initialState);\n        if (Array.isArray(this.cell.stateSize)) {\n            return this.cell.stateSize.map(function (dim) { return dim > 1 ? K.tile(initialState, [1, dim]) : initialState; });\n        }\n        else {\n            return this.cell.stateSize > 1 ?\n                [K.tile(initialState, [1, this.cell.stateSize])] :\n                [initialState];\n        }\n    };\n    Object.defineProperty(RNN.prototype, \"trainableWeights\", {\n        get: function () {\n            if (!this.trainable) {\n                return [];\n            }\n            return this.cell.trainableWeights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(RNN.prototype, \"nonTrainableWeights\", {\n        get: function () {\n            if (!this.trainable) {\n                return this.cell.weights;\n            }\n            return this.cell.nonTrainableWeights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    RNN.prototype.getClassName = function () {\n        return 'RNN';\n    };\n    RNN.prototype.getConfig = function () {\n        var config = {\n            returnSequences: this.returnSequences,\n            returnState: this.returnState,\n            goBackwards: this.goBackwards,\n            stateful: this.stateful,\n            unroll: this.unroll,\n        };\n        if (this.numConstants != null) {\n            config.numConstants = this.numConstants;\n        }\n        var cellConfig = this.cell.getConfig();\n        config.cell = {\n            className: this.cell.getClassName(),\n            config: cellConfig,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    return RNN;\n}(topology_2.Layer));\nexports.RNN = RNN;\ngeneric_utils.ClassNameMap.register('RNN', RNN);\nvar RNNCell = (function (_super) {\n    __extends(RNNCell, _super);\n    function RNNCell() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    RNNCell = __decorate([\n        tfjs_core_1.doc({ heading: 'Layers', subheading: 'Classes' })\n    ], RNNCell);\n    return RNNCell;\n}(topology_2.Layer));\nexports.RNNCell = RNNCell;\nvar SimpleRNNCell = (function (_super) {\n    __extends(SimpleRNNCell, _super);\n    function SimpleRNNCell(config) {\n        var _this = _super.call(this, config) || this;\n        _this.DEFAULT_ACTIVATION = 'tanh';\n        _this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        _this.DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n        _this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        _this.units = config.units;\n        _this.activation = activations_1.getActivation(config.activation == null ? _this.DEFAULT_ACTIVATION :\n            config.activation);\n        _this.useBias = config.useBias == null ? true : config.useBias;\n        _this.kernelInitializer = initializers_1.getInitializer(config.kernelInitializer || _this.DEFAULT_KERNEL_INITIALIZER);\n        _this.recurrentInitializer = initializers_1.getInitializer(config.recurrentInitializer || _this.DEFAULT_RECURRENT_INITIALIZER);\n        _this.biasInitializer =\n            initializers_1.getInitializer(config.biasInitializer || _this.DEFAULT_BIAS_INITIALIZER);\n        _this.kernelRegularizer = regularizers_1.getRegularizer(config.kernelRegularizer);\n        _this.recurrentRegularizer = regularizers_1.getRegularizer(config.recurrentRegularizer);\n        _this.biasRegularizer = regularizers_1.getRegularizer(config.biasRegularizer);\n        _this.kernelConstraint = constraints_1.getConstraint(config.kernelConstraint);\n        _this.recurrentConstraint = constraints_1.getConstraint(config.recurrentConstraint);\n        _this.biasConstraint = constraints_1.getConstraint(config.biasConstraint);\n        _this.dropout = math_utils.min([1, math_utils.max([0, config.dropout == null ? 0 : config.dropout])]);\n        _this.recurrentDropout = math_utils.min([\n            1,\n            math_utils.max([0, config.recurrentDropout == null ? 0 : config.recurrentDropout])\n        ]);\n        _this.stateSize = _this.units;\n        return _this;\n    }\n    SimpleRNNCell.prototype.build = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        this.kernel = this.addWeight('kernel', [inputShape[inputShape.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        this.recurrentKernel = this.addWeight('recurrent_kernel', [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        else {\n            this.bias = null;\n        }\n        this.built = true;\n    };\n    SimpleRNNCell.prototype.call = function (inputs, kwargs) {\n        inputs = inputs;\n        if (inputs.length !== 2) {\n            throw new errors_1.ValueError(\"SimpleRNNCell expects 2 input Tensors, got \" + inputs.length + \".\");\n        }\n        var prevOutput = inputs[1];\n        inputs = inputs[0];\n        if (this.dropout !== 0 || this.recurrentDropout !== 0) {\n            throw new errors_1.NotImplementedError('Dropout is not implemented for SimpleRNNCell yet');\n        }\n        var h = K.dot(inputs, this.kernel.read());\n        if (this.bias != null) {\n            h = K.biasAdd(h, this.bias.read());\n        }\n        var output = K.add(h, K.dot(prevOutput, this.recurrentKernel.read()));\n        if (this.activation != null) {\n            output = this.activation(output);\n        }\n        return [output, output];\n    };\n    SimpleRNNCell.prototype.getClassName = function () {\n        return 'SimpleRNNCell';\n    };\n    SimpleRNNCell.prototype.getConfig = function () {\n        var config = {\n            units: this.units,\n            activation: activations_1.serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: initializers_1.serializeInitializer(this.kernelInitializer),\n            recurrentInitializer: initializers_1.serializeInitializer(this.recurrentInitializer),\n            biasInitializer: initializers_1.serializeInitializer(this.biasInitializer),\n            kernelRegularizer: regularizers_1.serializeRegularizer(this.kernelRegularizer),\n            recurrentRegularizer: regularizers_1.serializeRegularizer(this.recurrentRegularizer),\n            biasRegularizer: regularizers_1.serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: regularizers_1.serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: constraints_1.serializeConstraint(this.kernelConstraint),\n            recurrentConstraint: constraints_1.serializeConstraint(this.recurrentConstraint),\n            biasConstraint: constraints_1.serializeConstraint(this.biasConstraint),\n            dropout: this.dropout,\n            recurrentDropout: this.recurrentDropout,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    return SimpleRNNCell;\n}(RNNCell));\nexports.SimpleRNNCell = SimpleRNNCell;\ngeneric_utils.ClassNameMap.register('SimpleRNNCell', SimpleRNNCell);\nvar SimpleRNN = (function (_super) {\n    __extends(SimpleRNN, _super);\n    function SimpleRNN(config) {\n        var _this = this;\n        config.cell = new SimpleRNNCell(config);\n        _this = _super.call(this, config) || this;\n        return _this;\n    }\n    SimpleRNN.prototype.call = function (inputs, kwargs) {\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        return _super.prototype.call.call(this, inputs, { mask: mask, training: training, initialState: initialState });\n    };\n    Object.defineProperty(SimpleRNN.prototype, \"units\", {\n        get: function () {\n            return this.cell.units;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"activation\", {\n        get: function () {\n            return this.cell.activation;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"useBias\", {\n        get: function () {\n            return this.cell.useBias;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"kernelInitializer\", {\n        get: function () {\n            return this.cell.kernelInitializer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"recurrentInitializer\", {\n        get: function () {\n            return this.cell.recurrentInitializer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"biasInitializer\", {\n        get: function () {\n            return this.cell.biasInitializer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"kernelRegularizer\", {\n        get: function () {\n            return this.cell.kernelRegularizer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"recurrentRegularizer\", {\n        get: function () {\n            return this.cell.recurrentRegularizer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"biasRegularizer\", {\n        get: function () {\n            return this.cell.biasRegularizer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"kernelConstraint\", {\n        get: function () {\n            return this.cell.kernelConstraint;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"recurrentConstraint\", {\n        get: function () {\n            return this.cell.recurrentConstraint;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"biasConstraint\", {\n        get: function () {\n            return this.cell.biasConstraint;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"dropout\", {\n        get: function () {\n            return this.cell.dropout;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(SimpleRNN.prototype, \"recurrentDropout\", {\n        get: function () {\n            return this.cell.recurrentDropout;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    SimpleRNN.prototype.getClassName = function () {\n        return 'SimpleRNN';\n    };\n    SimpleRNN.prototype.getConfig = function () {\n        var config = {\n            units: this.units,\n            activation: activations_1.serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: initializers_1.serializeInitializer(this.kernelInitializer),\n            recurrentInitializer: initializers_1.serializeInitializer(this.recurrentInitializer),\n            biasInitializer: initializers_1.serializeInitializer(this.biasInitializer),\n            kernelRegularizer: regularizers_1.serializeRegularizer(this.kernelRegularizer),\n            recurrentRegularizer: regularizers_1.serializeRegularizer(this.recurrentRegularizer),\n            biasRegularizer: regularizers_1.serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: regularizers_1.serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: constraints_1.serializeConstraint(this.kernelConstraint),\n            recurrentConstraint: constraints_1.serializeConstraint(this.recurrentConstraint),\n            biasConstraint: constraints_1.serializeConstraint(this.biasConstraint),\n            dropout: this.dropout,\n            recurrentDropout: this.recurrentDropout,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    return SimpleRNN;\n}(RNN));\nexports.SimpleRNN = SimpleRNN;\ngeneric_utils.ClassNameMap.register('SimpleRNN', SimpleRNN);\nvar GRUCell = (function (_super) {\n    __extends(GRUCell, _super);\n    function GRUCell(config) {\n        var _this = _super.call(this, config) || this;\n        _this.DEFAULT_ACTIVATION = 'tanh';\n        _this.DEFAULT_RECURRENT_ACTIVATION = 'hardSigmoid';\n        _this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        _this.DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n        _this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        _this.units = config.units;\n        _this.activation = activations_1.getActivation(config.activation === undefined ? _this.DEFAULT_ACTIVATION :\n            config.activation);\n        _this.recurrentActivation = activations_1.getActivation(config.activation === undefined ? _this.DEFAULT_RECURRENT_ACTIVATION :\n            config.recurrentActivation);\n        _this.useBias = config.useBias == null ? true : config.useBias;\n        _this.kernelInitializer = initializers_1.getInitializer(config.kernelInitializer || _this.DEFAULT_KERNEL_INITIALIZER);\n        _this.recurrentInitializer = initializers_1.getInitializer(config.recurrentInitializer || _this.DEFAULT_RECURRENT_INITIALIZER);\n        _this.biasInitializer =\n            initializers_1.getInitializer(config.biasInitializer || _this.DEFAULT_BIAS_INITIALIZER);\n        _this.kernelRegularizer = regularizers_1.getRegularizer(config.kernelRegularizer);\n        _this.recurrentRegularizer = regularizers_1.getRegularizer(config.recurrentRegularizer);\n        _this.biasRegularizer = regularizers_1.getRegularizer(config.biasRegularizer);\n        _this.kernelConstraint = constraints_1.getConstraint(config.kernelConstraint);\n        _this.recurrentConstraint = constraints_1.getConstraint(config.recurrentConstraint);\n        _this.biasConstraint = constraints_1.getConstraint(config.biasConstraint);\n        _this.dropout = math_utils.min([1, math_utils.max([0, config.dropout == null ? 0 : config.dropout])]);\n        _this.recurrentDropout = math_utils.min([\n            1,\n            math_utils.max([0, config.recurrentDropout == null ? 0 : config.recurrentDropout])\n        ]);\n        _this.implementation = config.implementation;\n        _this.stateSize = _this.units;\n        return _this;\n    }\n    GRUCell.prototype.build = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        var inputDim = inputShape[inputShape.length - 1];\n        this.kernel = this.addWeight('kernel', [inputDim, this.units * 3], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        this.recurrentKernel = this.addWeight('recurrent_kernel', [this.units, this.units * 3], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.units * 3], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        else {\n            this.bias = null;\n        }\n        this.built = true;\n    };\n    GRUCell.prototype.call = function (inputs, kwargs) {\n        if (this.dropout !== 0 || this.recurrentDropout !== 0) {\n            throw new errors_1.NotImplementedError('Dropout is not implemented for GRUCell yet');\n        }\n        inputs = inputs;\n        if (inputs.length !== 2) {\n            throw new errors_1.ValueError(\"GRUCell expects 2 input Tensors (inputs, h, c), got \" +\n                (inputs.length + \".\"));\n        }\n        var hTMinus1 = inputs[1];\n        inputs = inputs[0];\n        var z;\n        var r;\n        var hh;\n        if (this.implementation === 1) {\n            var kernelZ = K.sliceAlongLastAxis(this.kernel.read(), 0, this.units);\n            var kernelR = K.sliceAlongLastAxis(this.kernel.read(), this.units, this.units);\n            var kernelH = K.sliceAlongLastAxis(this.kernel.read(), this.units * 2, this.units);\n            var recurrentKernelZ = K.sliceAlongLastAxis(this.recurrentKernel.read(), 0, this.units);\n            var recurrentKernelR = K.sliceAlongLastAxis(this.recurrentKernel.read(), this.units, this.units);\n            var recurrentKernelH = K.sliceAlongLastAxis(this.recurrentKernel.read(), this.units * 2, this.units);\n            var inputsZ = inputs;\n            var inputsR = inputs;\n            var inputsH = inputs;\n            var xZ = K.dot(inputsZ, kernelZ);\n            var xR = K.dot(inputsR, kernelR);\n            var xH = K.dot(inputsH, kernelH);\n            if (this.useBias) {\n                var biasZ = K.sliceAlongFirstAxis(this.bias.read(), 0, this.units);\n                var biasR = K.sliceAlongFirstAxis(this.bias.read(), this.units, this.units);\n                var biasH = K.sliceAlongFirstAxis(this.bias.read(), this.units * 2, this.units);\n                xZ = K.biasAdd(xZ, biasZ);\n                xR = K.biasAdd(xR, biasR);\n                xH = K.biasAdd(xH, biasH);\n            }\n            var hTMinus1Z = hTMinus1;\n            var hTMinus1R = hTMinus1;\n            var hTMinus1H = hTMinus1;\n            z = this.recurrentActivation(K.add(xZ, K.dot(hTMinus1Z, recurrentKernelZ)));\n            r = this.recurrentActivation(K.add(xR, K.dot(hTMinus1R, recurrentKernelR)));\n            hh = this.activation(K.add(xH, K.dot(K.multiply(r, hTMinus1H), recurrentKernelH)));\n        }\n        else {\n            var matrixX = K.dot(inputs, this.kernel.read());\n            if (this.useBias) {\n                matrixX = K.biasAdd(matrixX, this.bias.read());\n            }\n            var matrixInner = K.dot(hTMinus1, K.sliceAlongLastAxis(this.recurrentKernel.read(), 0, 2 * this.units));\n            var xZ = K.sliceAlongLastAxis(matrixX, 0, this.units);\n            var xR = K.sliceAlongLastAxis(matrixX, this.units, this.units);\n            var recurrentZ = K.sliceAlongLastAxis(matrixInner, 0, this.units);\n            var recurrentR = K.sliceAlongLastAxis(matrixInner, this.units, this.units);\n            z = this.recurrentActivation(K.add(xZ, recurrentZ));\n            r = this.recurrentActivation(K.add(xR, recurrentR));\n            var xH = K.sliceAlongLastAxis(matrixX, 2 * this.units, this.units);\n            var recurrentH = K.dot(K.multiply(r, hTMinus1), K.sliceAlongLastAxis(this.recurrentKernel.read(), 2 * this.units, this.units));\n            hh = this.activation(K.add(xH, recurrentH));\n        }\n        var h = K.add(K.multiply(z, hTMinus1), K.multiply(K.scalarPlusArray(K.getScalar(1), K.neg(z)), hh));\n        return [h, h];\n    };\n    GRUCell.prototype.getClassName = function () {\n        return 'GRUCell';\n    };\n    GRUCell.prototype.getConfig = function () {\n        var config = {\n            units: this.units,\n            activation: activations_1.serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: initializers_1.serializeInitializer(this.kernelInitializer),\n            recurrentInitializer: initializers_1.serializeInitializer(this.recurrentInitializer),\n            biasInitializer: initializers_1.serializeInitializer(this.biasInitializer),\n            kernelRegularizer: regularizers_1.serializeRegularizer(this.kernelRegularizer),\n            recurrentRegularizer: regularizers_1.serializeRegularizer(this.recurrentRegularizer),\n            biasRegularizer: regularizers_1.serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: regularizers_1.serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: constraints_1.serializeConstraint(this.kernelConstraint),\n            recurrentConstraint: constraints_1.serializeConstraint(this.recurrentConstraint),\n            biasConstraint: constraints_1.serializeConstraint(this.biasConstraint),\n            dropout: this.dropout,\n            recurrentDropout: this.recurrentDropout,\n            implementation: this.implementation,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    return GRUCell;\n}(RNNCell));\nexports.GRUCell = GRUCell;\ngeneric_utils.ClassNameMap.register('GRUCell', GRUCell);\nvar GRU = (function (_super) {\n    __extends(GRU, _super);\n    function GRU(config) {\n        var _this = this;\n        if (config.implementation === 0) {\n            console.warn('`implementation=0` has been deprecated, and now defaults to ' +\n                '`implementation=1`. Please update your layer call.');\n        }\n        config.cell = new GRUCell(config);\n        _this = _super.call(this, config) || this;\n        return _this;\n    }\n    GRU.prototype.call = function (inputs, kwargs) {\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        return _super.prototype.call.call(this, inputs, { mask: mask, training: training, initialState: initialState });\n    };\n    Object.defineProperty(GRU.prototype, \"units\", {\n        get: function () {\n            return this.cell.units;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"activation\", {\n        get: function () {\n            return this.cell.activation;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"useBias\", {\n        get: function () {\n            return this.cell.useBias;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"kernelInitializer\", {\n        get: function () {\n            return this.cell.kernelInitializer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"recurrentInitializer\", {\n        get: function () {\n            return this.cell.recurrentInitializer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"biasInitializer\", {\n        get: function () {\n            return this.cell.biasInitializer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"kernelRegularizer\", {\n        get: function () {\n            return this.cell.kernelRegularizer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"recurrentRegularizer\", {\n        get: function () {\n            return this.cell.recurrentRegularizer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"biasRegularizer\", {\n        get: function () {\n            return this.cell.biasRegularizer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"kernelConstraint\", {\n        get: function () {\n            return this.cell.kernelConstraint;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"recurrentConstraint\", {\n        get: function () {\n            return this.cell.recurrentConstraint;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"biasConstraint\", {\n        get: function () {\n            return this.cell.biasConstraint;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"dropout\", {\n        get: function () {\n            return this.cell.dropout;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"recurrentDropout\", {\n        get: function () {\n            return this.cell.recurrentDropout;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(GRU.prototype, \"implementation\", {\n        get: function () {\n            return this.cell.implementation;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    GRU.prototype.getClassName = function () {\n        return 'GRU';\n    };\n    GRU.prototype.getConfig = function () {\n        var config = {\n            units: this.units,\n            activation: activations_1.serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: initializers_1.serializeInitializer(this.kernelInitializer),\n            recurrentInitializer: initializers_1.serializeInitializer(this.recurrentInitializer),\n            biasInitializer: initializers_1.serializeInitializer(this.biasInitializer),\n            kernelRegularizer: regularizers_1.serializeRegularizer(this.kernelRegularizer),\n            recurrentRegularizer: regularizers_1.serializeRegularizer(this.recurrentRegularizer),\n            biasRegularizer: regularizers_1.serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: regularizers_1.serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: constraints_1.serializeConstraint(this.kernelConstraint),\n            recurrentConstraint: constraints_1.serializeConstraint(this.recurrentConstraint),\n            biasConstraint: constraints_1.serializeConstraint(this.biasConstraint),\n            dropout: this.dropout,\n            recurrentDropout: this.recurrentDropout,\n            implementation: this.implementation,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    GRU.fromConfig = function (cls, config) {\n        if (config['implmentation'] === 0) {\n            config['implementation'] = 1;\n        }\n        return new cls(config);\n    };\n    return GRU;\n}(RNN));\nexports.GRU = GRU;\ngeneric_utils.ClassNameMap.register('GRU', GRU);\nvar LSTMCell = (function (_super) {\n    __extends(LSTMCell, _super);\n    function LSTMCell(config) {\n        var _this = _super.call(this, config) || this;\n        _this.DEFAULT_ACTIVATION = 'tanh';\n        _this.DEFAULT_RECURRENT_ACTIVATION = 'hardSigmoid';\n        _this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        _this.DEFAULT_RECURRENT_INITIALIZER = 'orthogonal';\n        _this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        _this.units = config.units;\n        _this.activation = activations_1.getActivation(config.activation === undefined ? _this.DEFAULT_ACTIVATION :\n            config.activation);\n        _this.recurrentActivation = activations_1.getActivation(config.activation === undefined ? _this.DEFAULT_RECURRENT_ACTIVATION :\n            config.recurrentActivation);\n        _this.useBias = config.useBias == null ? true : config.useBias;\n        _this.kernelInitializer = initializers_1.getInitializer(config.kernelInitializer || _this.DEFAULT_KERNEL_INITIALIZER);\n        _this.recurrentInitializer = initializers_1.getInitializer(config.recurrentInitializer || _this.DEFAULT_RECURRENT_INITIALIZER);\n        _this.biasInitializer =\n            initializers_1.getInitializer(config.biasInitializer || _this.DEFAULT_BIAS_INITIALIZER);\n        _this.unitForgetBias = config.unitForgetBias;\n        _this.kernelRegularizer = regularizers_1.getRegularizer(config.kernelRegularizer);\n        _this.recurrentRegularizer = regularizers_1.getRegularizer(config.recurrentRegularizer);\n        _this.biasRegularizer = regularizers_1.getRegularizer(config.biasRegularizer);\n        _this.kernelConstraint = constraints_1.getConstraint(config.kernelConstraint);\n        _this.recurrentConstraint = constraints_1.getConstraint(config.recurrentConstraint);\n        _this.biasConstraint = constraints_1.getConstraint(config.biasConstraint);\n        _this.dropout = math_utils.min([1, math_utils.max([0, config.dropout == null ? 0 : config.dropout])]);\n        _this.recurrentDropout = math_utils.min([\n            1,\n            math_utils.max([0, config.recurrentDropout == null ? 0 : config.recurrentDropout])\n        ]);\n        _this.implementation = config.implementation;\n        _this.stateSize = [_this.units, _this.units];\n        return _this;\n    }\n    LSTMCell.prototype.build = function (inputShape) {\n        inputShape = generic_utils.getExactlyOneShape(inputShape);\n        var inputDim = inputShape[inputShape.length - 1];\n        this.kernel = this.addWeight('kernel', [inputDim, this.units * 4], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        this.recurrentKernel = this.addWeight('recurrent_kernel', [this.units, this.units * 4], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n        var biasInitializer;\n        if (this.useBias) {\n            if (this.unitForgetBias) {\n                var capturedBiasInit_1 = this.biasInitializer;\n                var capturedUnits_1 = this.units;\n                biasInitializer = new ((function (_super) {\n                    __extends(CustomInit, _super);\n                    function CustomInit() {\n                        return _super !== null && _super.apply(this, arguments) || this;\n                    }\n                    CustomInit.prototype.apply = function (shape, dtype) {\n                        var bI = capturedBiasInit_1.apply([capturedUnits_1]);\n                        var bF = (new initializers_1.Ones()).apply([capturedUnits_1]);\n                        var bCAndH = capturedBiasInit_1.apply([capturedUnits_1 * 2]);\n                        return K.concatAlongFirstAxis(K.concatAlongFirstAxis(bI, bF), bCAndH);\n                    };\n                    CustomInit.prototype.getClassName = function () {\n                        return 'CustomInit';\n                    };\n                    return CustomInit;\n                }(initializers_1.Initializer)))();\n            }\n            else {\n                biasInitializer = this.biasInitializer;\n            }\n            this.bias = this.addWeight('bias', [this.units * 4], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        else {\n            this.bias = null;\n        }\n        this.built = true;\n    };\n    LSTMCell.prototype.call = function (inputs, kwargs) {\n        if (this.dropout !== 0 || this.recurrentDropout !== 0) {\n            throw new errors_1.NotImplementedError('Dropout is not implemented for LSTMCell yet');\n        }\n        inputs = inputs;\n        if (inputs.length !== 3) {\n            throw new errors_1.ValueError(\"LSTMCell expects 3 input Tensors (inputs, h, c), got \" +\n                (inputs.length + \".\"));\n        }\n        var hTMinus1 = inputs[1];\n        var cTMinus1 = inputs[2];\n        inputs = inputs[0];\n        var i;\n        var f;\n        var c;\n        var o;\n        if (this.implementation === 1) {\n            var kernelI = K.sliceAlongLastAxis(this.kernel.read(), 0, this.units);\n            var kernelF = K.sliceAlongLastAxis(this.kernel.read(), this.units, this.units);\n            var kernelC = K.sliceAlongLastAxis(this.kernel.read(), this.units * 2, this.units);\n            var kernelO = K.sliceAlongLastAxis(this.kernel.read(), this.units * 3, this.units);\n            var recurrentKernelI = K.sliceAlongLastAxis(this.recurrentKernel.read(), 0, this.units);\n            var recurrentKernelF = K.sliceAlongLastAxis(this.recurrentKernel.read(), this.units, this.units);\n            var recurrentKernelC = K.sliceAlongLastAxis(this.recurrentKernel.read(), this.units * 2, this.units);\n            var recurrentKernelO = K.sliceAlongLastAxis(this.recurrentKernel.read(), this.units * 3, this.units);\n            var inputsI = inputs;\n            var inputsF = inputs;\n            var inputsC = inputs;\n            var inputsO = inputs;\n            var xI = K.dot(inputsI, kernelI);\n            var xF = K.dot(inputsF, kernelF);\n            var xC = K.dot(inputsC, kernelC);\n            var xO = K.dot(inputsO, kernelO);\n            if (this.useBias) {\n                var biasI = K.sliceAlongFirstAxis(this.bias.read(), 0, this.units);\n                var biasF = K.sliceAlongFirstAxis(this.bias.read(), this.units, this.units);\n                var biasC = K.sliceAlongFirstAxis(this.bias.read(), this.units * 2, this.units);\n                var biasO = K.sliceAlongFirstAxis(this.bias.read(), this.units * 3, this.units);\n                xI = K.biasAdd(xI, biasI);\n                xF = K.biasAdd(xF, biasF);\n                xC = K.biasAdd(xC, biasC);\n                xO = K.biasAdd(xO, biasO);\n            }\n            var hTMinus1I = hTMinus1;\n            var hTMinus1F = hTMinus1;\n            var hTMinus1C = hTMinus1;\n            var hTMinus1O = hTMinus1;\n            i = this.recurrentActivation(K.add(xI, K.dot(hTMinus1I, recurrentKernelI)));\n            f = this.recurrentActivation(K.add(xF, K.dot(hTMinus1F, recurrentKernelF)));\n            c = K.add(K.multiply(f, cTMinus1), K.multiply(i, this.activation(K.add(xC, K.dot(hTMinus1C, recurrentKernelC)))));\n            o = this.recurrentActivation(K.add(xO, K.dot(hTMinus1O, recurrentKernelO)));\n        }\n        else {\n            var z = K.dot(inputs, this.kernel.read());\n            z = K.add(z, K.dot(hTMinus1, this.recurrentKernel.read()));\n            if (this.useBias) {\n                z = K.biasAdd(z, this.bias.read());\n            }\n            var z0 = K.sliceAlongLastAxis(z, 0, this.units);\n            var z1 = K.sliceAlongLastAxis(z, this.units, this.units);\n            var z2 = K.sliceAlongLastAxis(z, this.units * 2, this.units);\n            var z3 = K.sliceAlongLastAxis(z, this.units * 3, this.units);\n            i = this.recurrentActivation(z0);\n            f = this.recurrentActivation(z1);\n            c = K.add(K.multiply(f, cTMinus1), K.multiply(i, this.activation(z2)));\n            o = this.recurrentActivation(z3);\n        }\n        var h = K.multiply(o, this.activation(c));\n        return [h, h, c];\n    };\n    LSTMCell.prototype.getClassName = function () {\n        return 'LSTMCell';\n    };\n    LSTMCell.prototype.getConfig = function () {\n        var config = {\n            units: this.units,\n            activation: activations_1.serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: initializers_1.serializeInitializer(this.kernelInitializer),\n            recurrentInitializer: initializers_1.serializeInitializer(this.recurrentInitializer),\n            biasInitializer: initializers_1.serializeInitializer(this.biasInitializer),\n            unitForgetBias: this.unitForgetBias,\n            kernelRegularizer: regularizers_1.serializeRegularizer(this.kernelRegularizer),\n            recurrentRegularizer: regularizers_1.serializeRegularizer(this.recurrentRegularizer),\n            biasRegularizer: regularizers_1.serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: regularizers_1.serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: constraints_1.serializeConstraint(this.kernelConstraint),\n            recurrentConstraint: constraints_1.serializeConstraint(this.recurrentConstraint),\n            biasConstraint: constraints_1.serializeConstraint(this.biasConstraint),\n            dropout: this.dropout,\n            recurrentDropout: this.recurrentDropout,\n            implementation: this.implementation,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    return LSTMCell;\n}(RNNCell));\nexports.LSTMCell = LSTMCell;\ngeneric_utils.ClassNameMap.register('LSTMCell', LSTMCell);\nvar LSTM = (function (_super) {\n    __extends(LSTM, _super);\n    function LSTM(config) {\n        var _this = this;\n        if (config.implementation === 0) {\n            console.warn('`implementation=0` has been deprecated, and now defaults to ' +\n                '`implementation=1`. Please update your layer call.');\n        }\n        config.cell = new LSTMCell(config);\n        _this = _super.call(this, config) || this;\n        return _this;\n    }\n    LSTM.prototype.call = function (inputs, kwargs) {\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        return _super.prototype.call.call(this, inputs, { mask: mask, training: training, initialState: initialState });\n    };\n    Object.defineProperty(LSTM.prototype, \"units\", {\n        get: function () {\n            return this.cell.units;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"activation\", {\n        get: function () {\n            return this.cell.activation;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"useBias\", {\n        get: function () {\n            return this.cell.useBias;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"kernelInitializer\", {\n        get: function () {\n            return this.cell.kernelInitializer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"recurrentInitializer\", {\n        get: function () {\n            return this.cell.recurrentInitializer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"biasInitializer\", {\n        get: function () {\n            return this.cell.biasInitializer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"unitForgetBias\", {\n        get: function () {\n            return this.cell.unitForgetBias;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"kernelRegularizer\", {\n        get: function () {\n            return this.cell.kernelRegularizer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"recurrentRegularizer\", {\n        get: function () {\n            return this.cell.recurrentRegularizer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"biasRegularizer\", {\n        get: function () {\n            return this.cell.biasRegularizer;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"kernelConstraint\", {\n        get: function () {\n            return this.cell.kernelConstraint;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"recurrentConstraint\", {\n        get: function () {\n            return this.cell.recurrentConstraint;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"biasConstraint\", {\n        get: function () {\n            return this.cell.biasConstraint;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"dropout\", {\n        get: function () {\n            return this.cell.dropout;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"recurrentDropout\", {\n        get: function () {\n            return this.cell.recurrentDropout;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(LSTM.prototype, \"implementation\", {\n        get: function () {\n            return this.cell.implementation;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    LSTM.prototype.getClassName = function () {\n        return 'LSTM';\n    };\n    LSTM.prototype.getConfig = function () {\n        var config = {\n            units: this.units,\n            activation: activations_1.serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: initializers_1.serializeInitializer(this.kernelInitializer),\n            recurrentInitializer: initializers_1.serializeInitializer(this.recurrentInitializer),\n            biasInitializer: initializers_1.serializeInitializer(this.biasInitializer),\n            unitForgetBias: this.unitForgetBias,\n            kernelRegularizer: regularizers_1.serializeRegularizer(this.kernelRegularizer),\n            recurrentRegularizer: regularizers_1.serializeRegularizer(this.recurrentRegularizer),\n            biasRegularizer: regularizers_1.serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: regularizers_1.serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: constraints_1.serializeConstraint(this.kernelConstraint),\n            recurrentConstraint: constraints_1.serializeConstraint(this.recurrentConstraint),\n            biasConstraint: constraints_1.serializeConstraint(this.biasConstraint),\n            dropout: this.dropout,\n            recurrentDropout: this.recurrentDropout,\n            implementation: this.implementation,\n        };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    LSTM.fromConfig = function (cls, config) {\n        if (config['implmentation'] === 0) {\n            config['implementation'] = 1;\n        }\n        return new cls(config);\n    };\n    return LSTM;\n}(RNN));\nexports.LSTM = LSTM;\ngeneric_utils.ClassNameMap.register('LSTM', LSTM);\nvar StackedRNNCells = (function (_super) {\n    __extends(StackedRNNCells, _super);\n    function StackedRNNCells(config) {\n        var _this = _super.call(this, config) || this;\n        _this.cells = config.cells;\n        return _this;\n    }\n    Object.defineProperty(StackedRNNCells.prototype, \"stateSize\", {\n        get: function () {\n            var stateSize = [];\n            for (var _i = 0, _a = this.cells.slice().reverse(); _i < _a.length; _i++) {\n                var cell = _a[_i];\n                if (Array.isArray(cell.stateSize)) {\n                    stateSize.push.apply(stateSize, cell.stateSize);\n                }\n                else {\n                    stateSize.push(cell.stateSize);\n                }\n            }\n            return stateSize;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    StackedRNNCells.prototype.call = function (inputs, kwargs) {\n        inputs = inputs;\n        var states = inputs.slice(1);\n        var nestedStates = [];\n        for (var _i = 0, _a = this.cells.slice().reverse(); _i < _a.length; _i++) {\n            var cell = _a[_i];\n            if (Array.isArray(cell.stateSize)) {\n                nestedStates.push(states.splice(0, cell.stateSize.length));\n            }\n            else {\n                nestedStates.push(states.splice(0, 1));\n            }\n        }\n        nestedStates.reverse();\n        var newNestedStates = [];\n        var callInputs;\n        for (var i = 0; i < this.cells.length; ++i) {\n            var cell = this.cells[i];\n            states = nestedStates[i];\n            if (i === 0) {\n                callInputs = [inputs[0]].concat(states);\n            }\n            else {\n                callInputs = [callInputs[0]].concat(states);\n            }\n            callInputs = cell.call(callInputs, kwargs);\n            newNestedStates.push(callInputs.slice(1));\n        }\n        states = [];\n        for (var _b = 0, _c = newNestedStates.slice().reverse(); _b < _c.length; _b++) {\n            var cellStates = _c[_b];\n            states.push.apply(states, cellStates);\n        }\n        return [callInputs[0]].concat(states);\n    };\n    StackedRNNCells.prototype.build = function (inputShape) {\n        if (generic_utils.isArrayOfShapes(inputShape)) {\n            inputShape = inputShape[0];\n        }\n        inputShape = inputShape;\n        var outputDim;\n        for (var _i = 0, _a = this.cells; _i < _a.length; _i++) {\n            var cell = _a[_i];\n            cell.build(inputShape);\n            if (Array.isArray(cell.stateSize)) {\n                outputDim = cell.stateSize[0];\n            }\n            else {\n                outputDim = cell.stateSize;\n            }\n            inputShape = [inputShape[0], outputDim];\n        }\n        this.built = true;\n    };\n    StackedRNNCells.prototype.getClassName = function () {\n        return 'StackedRNNCells';\n    };\n    StackedRNNCells.prototype.getConfig = function () {\n        var cellConfigs = [];\n        for (var _i = 0, _a = this.cells; _i < _a.length; _i++) {\n            var cell = _a[_i];\n            cellConfigs.push({\n                'className': this.getClassName(),\n                'config': cell.getConfig(),\n            });\n        }\n        var config = { 'cells': cellConfigs };\n        var baseConfig = _super.prototype.getConfig.call(this);\n        Object.assign(config, baseConfig);\n        return config;\n    };\n    StackedRNNCells.fromConfig = function (cls, config, customObjects) {\n        if (customObjects === void 0) { customObjects = {}; }\n        var cells = [];\n        for (var _i = 0, _a = config['cells']; _i < _a.length; _i++) {\n            var cellConfig = _a[_i];\n            cells.push(serialization_1.deserialize(cellConfig, customObjects));\n        }\n        return new cls({ cells: cells });\n    };\n    Object.defineProperty(StackedRNNCells.prototype, \"trainableWeights\", {\n        get: function () {\n            if (!this.trainable) {\n                return [];\n            }\n            var weights = [];\n            for (var _i = 0, _a = this.cells; _i < _a.length; _i++) {\n                var cell = _a[_i];\n                weights.push.apply(weights, cell.trainableWeights);\n            }\n            return weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(StackedRNNCells.prototype, \"nonTrainableWeights\", {\n        get: function () {\n            var weights = [];\n            for (var _i = 0, _a = this.cells; _i < _a.length; _i++) {\n                var cell = _a[_i];\n                weights.push.apply(weights, cell.nonTrainableWeights);\n            }\n            if (!this.trainable) {\n                var trainableWeights = [];\n                for (var _b = 0, _c = this.cells; _b < _c.length; _b++) {\n                    var cell = _c[_b];\n                    trainableWeights.push.apply(trainableWeights, cell.trainableWeights);\n                }\n                return trainableWeights.concat(weights);\n            }\n            return weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    StackedRNNCells.prototype.getWeights = function () {\n        var weights = [];\n        for (var _i = 0, _a = this.cells; _i < _a.length; _i++) {\n            var cell = _a[_i];\n            weights.push.apply(weights, cell.weights);\n        }\n        return K.batchGetValue(weights);\n    };\n    StackedRNNCells.prototype.setWeights = function (weights) {\n        var tuples = [];\n        for (var _i = 0, _a = this.cells; _i < _a.length; _i++) {\n            var cell = _a[_i];\n            var numParams = cell.weights.length;\n            var inputWeights = weights.splice(numParams);\n            for (var i = 0; i < cell.weights.length; ++i) {\n                tuples.push([cell.weights[i], inputWeights[i]]);\n            }\n        }\n        K.batchSetValue(tuples);\n    };\n    return StackedRNNCells;\n}(RNNCell));\nexports.StackedRNNCells = StackedRNNCells;\ngeneric_utils.ClassNameMap.register('StackedRNNCells', StackedRNNCells);\n"},"hash":"903474d2ba4e8503c6b8b2ec867ab32e","cacheData":{"env":{}}}